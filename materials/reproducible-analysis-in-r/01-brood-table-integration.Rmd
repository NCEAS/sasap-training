# Example: Brood Table Analysis

## Introduction

```{r package loading, echo = FALSE, warning = FALSE, message = FALSE}
library(readxl)
library(ggplot2) # For making plots at the end
library(kableExtra)
library(leaflet)
library(knitr)
library(dplyr)
```

Brood tables, also called run reconstructions, utilize annual estimates of the total run (commercial catch plus escapement), and samples of ages, to estimate the number of recruits per age class. These data are useful for salmon biologists to understand salmon productivity and salmon life histories.

These data can come in a number of different formats, but generally follow the pattern of:
1. Rows for each brood year
2. Columnas for the estimated number of fish in each age class.

See the example below, showing a Sockeye salmon brood table from the Goodnews River, Alaska:

![](images/GoodnewsHeader.png)



Sometimes other columns are included, such as return years in this example (again for Sockeye salmon) from Coghill Lake, Alaska:

![](images/CoghillHeader.png)



If you are interested in analysing trends across multiple stocks, the many different ways brood tables can be presented make integrating multiple brood tables a big challenge. In this exercise we will intoduce some ways to reformat, merge, and reshape a set brood tables from around the state of Alaska. These datasets were gathered as part of the SASAP research from a number of different ADFG offices. We will start with the raw (unmodified) data for each stock, run each stockâ€™s brood table through a separate R script to normalize the format, integrate all of the brood tables together, and finally do an exploratory analysis across stocks.

## Datasets

As part of the SASAP project, brood tables for 48 Sockeye salmon stocks were collected. Table 2.1 shows a list of these stocks, along with other regional and location information.

```{r, echo = FALSE}
stocks <- read.csv('data/original/StockInfo.csv', stringsAsFactors = F)

```

```{r, echo = FALSE}
kable(stocks, row.names = F, format = 'html', caption = 'Stock information', align = 'c') %>% 
        kable_styling(bootstrap_options = c('table','hover','condensed','responsive'), font_size = 8, position = 'center') #%>%
```




Source information, including who initially requested the data and the year in which it was obtained, is shown in Table 2. THIS TABLE IS TOO LONG AND I HATE THE STRIPES



```{r, echo = FALSE}
source <- read.csv('data/original/source_information.csv', stringsAsFactors = F)
kable(source, row.names = F, format = 'html', caption = 'Source information', align = 'c') %>% 
        kable_styling(bootstrap_options = c('table','hover', 'condensed', 'responsive'), font_size = 8, position = 'center') #%>%
```



These stocks range geographically from Washington to Alaska. Although temporal coverage varies by stock, many of the brood tables were updated in 2016, and some have reconstructions dating back to 1922. 



Figure 2.1 indicates the approximate location of the salmon stocks in Table 2.1.

```{r, echo = FALSE}
salmon = makeIcon('/home/sjclark/sasap-training/materials/reproducible-analysis-in-r/data/images/salmon_tiny.png',
                  '/home/sjclark/sasap-training/materials/reproducible-analysis-in-r/data/images/salmon_big.png',
                  26, 14)

m <- leaflet(stocks)  %>%
  setView(-median(stocks$Lon), median(stocks$Lat), zoom = 4) %>%
  addTiles() %>% 
  addMarkers(~-Lon, ~Lat, icon = salmon)

m

```
Figure 2.1: Location of stocks used in this data integration. Salmonid icon by Servien (vectorized by T. Michael Keesey) [License](https://creativecommons.org/licenses/by-sa/3.0/)

## Reformatting

First we need to change the brood table column names so that they are in a consistent format. Here we show an example of how one of our source tables (Coghill Lake, from above) is reformatted. Prior to diving into reformatting, it is good to have an idea of what columns will be necessary in your merged data table. To identify different stocks, certainly a column will be needed for the stock name (usually a river name) and the species. If you wish to analyze across different regions or areas, you may want to have a column for region as well. Of course you will also need columns for brood year and all of the possible age classes you might encounter. A quality flag indicating whether data should be used in analysis or not based on set critera is also useful. Finally, it is also a good idea to have a unique identifier for each brood table that goes into the merged data table so that you can easily add data by stock, or summarize data by stock. With that in mind, we will be reformatting all of the brood tables so they have the following column names:

|Stock Information| Run Information | Age Classes|
|:------:|:------:|:-------:|
|'Stock.ID'|'BroodYear'|'R0.1' 'R1.1' 'R2.1' 'R3.1' 'R4.1'|
|'Species'|'TotalEscapement'|'R0.2' 'R1.2' 'R2.2' 'R3.2' 'R4.2'|
|'Region'||'R0.3' 'R1.3' 'R2.3' 'R3.3' 'R4.3'|
|'Sub.Region'||'R0.4' 'R1.4' 'R2.4' 'R3.4' 'R4.4'|
|'UseFlag'||'R0.5' 'R1.5' 'R2.5' 'R3.5' 'R4.5'|
```
'Stock.ID', 'Species', 'Stock','Region','Sub.Region','UseFlag',
'BroodYear','TotalEscapement',
'R0.1','R0.2', 'R0.3','R0.4',	'R0.5',
'R1.1','R1.2','R1.3','R1.4','R1.5', 
'R2.1','R2.2','R2.3','R2.4','R2.5',
'R3.1','R3.2','R3.3','R3.4',
'R4.1','R4.2' ,'R4.3'
```

First we need to load any packages. 


Now read in the file, skipping the first 6 lines before the true header row on line 7, and check the column names

```{r read}
b <- read_excel('data/original/112_COGHILL_BROOD_TABLE.xls', skip = 6)
colnames(b)
```

There are definitely some redundant and confusing columns here that we need to remove, and some we need to add according to the list above. First we remove the columns we don't want - namely all of the return years, the total return, and recruits/spawner. Note that we can always calculate these columns again later from the rest of the data.

```{r clean up columns}
#delete columns by column name
b$Year__1 <- NULL
b$Year__2 <- NULL
b$Year__3 <- NULL
b$Year__4 <- NULL
b$Year__5 <- NULL
b$Year__6 <- NULL
b$Return <- NULL
b$Return__1 <- NULL
b$`Return/spawner` <- NULL
```

Now we need to fill in the information that is missing by adding columns:
```'Stock.ID', 'Species', 'Stock','Region','Sub.Region','UseFlag'```

```{r add columns}
#add stock information columns
b$Stock.ID <- 139 #preassigned Stock.ID
b$Species <- 'Sockeye'
b$Stock <- 'Coghill'
b$Region <- 'PWS'
b$Sub.Region <- 'PWS'
b$UseFlag <- 1
```

Note that since we have no reason to suspect any data are not up to quality standards yet, we fill the `UseFlag` columns with 1s.

Let's do another check on column names now.

```{r colnames check}
colnames(b)
```

Getting close, but these are not quite in the format that we decided on so we will rename them.

```{r rename columns}
colnames(b) <- c("BroodYear", "TotalEscapement","R1.1","R0.2","R0.3","R1.2","R2.1","R1.3","R2.2",  
"R1.4","R2.3","R2.4","Stock.ID","Species",'Stock',"Region","Sub.Region","UseFlag")
```

Finally, you may want to reorder the columns into something more intuitive.
```{r reorder columns}
b <- b[, c('Stock.ID', 'Species', 'Stock','Region','Sub.Region', 'UseFlag',
           'BroodYear','TotalEscapement','R0.2', 'R0.3',
           'R1.1','R1.2','R1.3','R1.4', 
           'R2.1','R2.2','R2.3','R2.4')]
```

And very lastly, write the file to a new directory where all of the individually reformatted brood tables will be kept.

```{r write file, eval = F}
write.csv(b, 'Coghill_sockeye.csv', row.names = F)
```

## Batch Reformatting

Once a reformatting script has been written for all of the data files that are going to be incorporated, we can write another script that will run all of those scripts at once. In this case, I use a nicely written function from [stack overflow](https://stackoverflow.com/a/20083589)

```{r source folder}
sourceEntireFolder <- function(folderName, verbose=FALSE, showWarnings=TRUE) { 
    files <- list.files(folderName, full.names=TRUE)
    
    # Grab only R files
    files <- files[ grepl("\\.[rR]$", files) ]
    
    if (!length(files) && showWarnings)
        warning("No R files in ", folderName)
    
    for (f in files) {
        if (verbose)
            cat("sourcing: ", f, "\n")
        try(source(f, local=FALSE, echo=FALSE), silent=!verbose)
    }
    return(invisible(NULL))
}
```


```{r run sourcefolder, eval = F, warning=FALSE, message = FALSE}
t <- sourceEntireFolder('data/data_formatting_scripts/', verbose = T)
```

## Merging

Now that all of the data tables have been reformatted, we can read them in and merge them into a single file. We use the function `rbind.fill` here to merge the files together since some of these files have age classes that others don't. The `rbind.fill` function adds in all columns that exist, filling in the columns that don't have values for a particular stock with `NA`.

```{r merge}
readmerge <- function(path1){
    files <- dir(path1, include.dirs = FALSE)
    files <- files[ grepl(".csv", files) ]
    a <- do.call(bind_rows,lapply(file.path(path1,files),read.csv, stringsAsFactors = F))
    #NEED TO FIGURE OUT HOW TO USE RBIND.FILL TO FILL WITH ZEROS HERE
    return(a)
}

path1 <- 'data/reformatted/'
b <- readmerge(path1)
```

Using `rbind.fill` made the column order a little strange, so we'll rearrange again.

```{r rearrange again}
#rearrange columns
b <- b[, c('Stock.ID', 'Species', 'Stock','Region','Sub.Region', 'UseFlag','BroodYear',
                'TotalEscapement','R0.1','R0.2', 'R0.3','R0.4',	'R0.5',
                'R1.1','R1.2','R1.3','R1.4','R1.5', 
                'R2.1','R2.2','R2.3','R2.4','R2.5',
                'R3.1','R3.2','R3.3','R3.4',
                'R4.1','R4.2' ,'R4.3')]
```


## Quality Assurance

Now we should do some checks to make sure that the data are up to standards and the reformatting was done correctly.

First, for character columns, check that unique values are as expected.

```{r unique character columns}
charCol <- which(lapply(b, class) == 'character') #use lapply and which to find index of columns that are of class "character"

for (i in 1:length(charCol)){
    print(colnames(b)[charCol[i]]) #print column name
   print(unique(b[, charCol[i]])) #display unique values for that column
}

```

For numeric/integer columns, the `summary` function gives a nice overview of the range, distribution, and number of `NA` values.

```{r summary of numeric columns}
numCol <- which(lapply(b, class) != 'character') #use lapply and which to find index of columns that are of class "character"
summary(b[, numCol])
```


From here, I can go into writing more QA functions or we can go ahead and melt the dataframe. Open to suggestions from you Bryce

## Analysis

Now that we've done all of the work to clean and integrate all of the individual brood tables into a single `data.frame`, we're ready to start exploring how the regions, sub-regions, and individual stocks might differ.
A very common use of brood table data is to produce run size forecasts using the information we obtained by splitting returns into individual age classes.
This approach revolves around the idea that productivity ($R/S$) for each age class is likely to be relatively more correlated within brood years than across brood years and that adults of some species of salmon (e.g., sockeye) have multiple return years for a given brood year.
This lets us borrow information from the absolute number of earlier-returning (e.g., 1.2) individuals to make a guess about how many older individuals from that same brood year will return.

Below, I show two sets of scatterplots of the number of age 1.3 fish against the number of age 1.2 fish. Each panel is overlaid with regressions about the origin.

### Relationship between 1.2s and 1.3s by Region

```{r, warning=FALSE}
ggplot(b, aes(R1.2, R1.3)) + 
  geom_point() + 
  geom_smooth(method = "lm", 
              formula = "y ~ 0 + x", 
              se = FALSE) + 
  facet_wrap(~ Region,
             scales = "free")
```

Note that the scales are not fixed so comparing slopes across panels does not make sense.
Because we're using R, we could easily extract such information.

### Relationship between 1.2s and 1.3s by Stock

The same type of plot can easily be produced for a different grouping level, such as stock:

```{r, warning=FALSE}
ggplot(b, aes(R1.2, R1.3)) + 
  geom_point() + 
  geom_smooth(method = "lm", 
              formula = "y ~ 0 + x", 
              se = FALSE) + 
  facet_wrap(~ Stock,
             scales = "free")
```

Note that the scales are not fixed so comparing slopes across panels does not make sense.
